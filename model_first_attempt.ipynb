{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as fn\n",
    "import torchmetrics\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "WANDB_LOGGING = False\n",
    "FREEZE_FEATURE_EXTRACTOR = True\n",
    "CONFIG = {\n",
    "    \"project_name\": \"name\",\n",
    "    \"dataloader\": {\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    \"bias\": True,\n",
    "    \"lr\": 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardDetector(nn.Module):\n",
    "    def __init__(self, num_cells, num_anchors):\n",
    "        super(CardDetector, self).__init__()\n",
    "\n",
    "        self.num_cells = num_cells\n",
    "        self.num_anchors = num_anchors\n",
    "        \n",
    "        self.feature_extractor = models.resnet18(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.feature_extractor.children())[:-1])\n",
    "        if FREEZE_FEATURE_EXTRACTOR:\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.detection_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, self.num_cells * self.num_anchors * 5, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        features = self.feature_extractor(input)\n",
    "\n",
    "        detection = self.detection_head(features)\n",
    "        detection = detection.permute(0, 2, 3, 1)\n",
    "        \n",
    "        detection = detection.view(-1, self.num_cells * self.num_anchors, 5)\n",
    "        detection[:, :, 0] = torch.sigmoid(detection[:, :, 0])\n",
    "        \n",
    "        return detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardDetectorMultiBox(nn.Module):\n",
    "    def __init__(self, num_anchors, num_cells, max_boxes=5):\n",
    "        super(CardDetectorMultiBox, self).__init__()\n",
    "\n",
    "        self.num_anchors = num_anchors\n",
    "        self.num_cells = num_cells\n",
    "        self.max_boxes = max_boxes\n",
    "        \n",
    "        self.detector = CardDetector(num_anchors=num_anchors, num_cells=num_cells)\n",
    "\n",
    "        self.box_regression_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, max_boxes * 4, kernel_size=1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(max_boxes, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, max_boxes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        features = self.detector.feature_extractor(input)\n",
    "\n",
    "        detection = self.detector(input)\n",
    "        box_regression = self.box_regression_head(features)\n",
    "\n",
    "        #print(f\"detection:{detection.shape}, box_reg:{box_regression.shape}\")\n",
    "\n",
    "        attention_weights = self.attention(detection)\n",
    "        num_boxes = torch.sum(attention_weights * self.max_boxes, dim=1)\n",
    "        num_boxes = torch.clamp(num_boxes, min=1, max=self.max_boxes)\n",
    "        num_boxes = num_boxes.int()\n",
    "\n",
    "        print(f\"detection:{detection.shape}, box_reg:{box_regression.shape}, attention_weights:{attention_weights.shape}, num_boxes:{num_boxes.shape}\")\n",
    "\n",
    "        detection_scores = detection[:, :, :1]\n",
    "        _, topk_indices = torch.topk(detection_scores, k=self.max_boxes, dim=1)\n",
    "        detection_topk = torch.gather(detection, dim=1, index=topk_indices)\n",
    "\n",
    "        print(f\"detection_scores:{detection_scores.shape}, topk_indices:{topk_indices.shape}, detection_topk:{detection_topk.shape}\")\n",
    "        print(f\"box_regression:{box_regression.shape}\")\n",
    "\n",
    "        box_regression_topk = torch.gather(box_regression, dim=1, index=topk_indices)\n",
    "\n",
    "\n",
    "     \n",
    "        boxes = []\n",
    "        return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # We use tqdm to display a simple progress bar, allowing us to observe the learning progression.\n",
    "\n",
    "def fit(\n",
    "  model: nn.Module,\n",
    "  num_epochs: int,\n",
    "  optimizer: torch.optim.Optimizer,\n",
    "  train_dataloader: DataLoader,\n",
    "  val_dataloader: DataLoader,\n",
    "  print_rate: int = 100\n",
    "  ):\n",
    "    # TODO: figure out accuacy\n",
    "    #accuracy = torchmetrics.Accuracy(task='multiclass', average=\"weighted\").to(model.device)\n",
    "    accuracy = None\n",
    "    model = model.to(model.device)\n",
    "    # Iterate through epochs with tqdm\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print(f\"Epoch: {epoch}\\n\")\n",
    "        train_loss = 0\n",
    "        model.train()  # Set mode of model to train\n",
    "        \n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            loss = model.train_step(X, y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Getting the loss gradient and making an optimizer step\n",
    "            optimizer.zero_grad()  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % print_rate == 0: \n",
    "                print(f\"Looked at {batch} Batches\\t---\\t{batch * len(X)}/{len(train_dataloader.dataset)} Samples\")\n",
    "            elif batch == len(train_dataloader) - 1:\n",
    "                print(f\"Looked at {batch} Batches\\t---\\t{len(train_dataloader.dataset)}/{len(train_dataloader.dataset)} Samples\")\n",
    "        \n",
    "        # Divide the train_loss by the number of batches to get the average train_loss\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "        # Validation\n",
    "        # Setup the Val Loss and Accuracy to accumulate over the batches in the val dataset\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        # Set model to evaluation mode and use torch.inference_mode to remove unnecessary training operations \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X_val, y_val in val_dataloader:\n",
    "                loss, acc = model.val_step(X_val, y_val, accuracy)\n",
    "                val_loss += loss.item()\n",
    "                val_acc += acc\n",
    "\n",
    "        # Get the average Val Loss and Accuracy\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        avg_val_acc = val_acc / len(val_dataloader)\n",
    "\n",
    "        print(f\"Train loss: {avg_train_loss} | Val Loss: {avg_val_loss} | Val Accuracy: {avg_val_acc}\")\n",
    "        if WANDB_LOGGING:\n",
    "            wandb.log({\"Train Loss\": avg_train_loss,\"Val Loss\": avg_val_loss, \"Val Accuracy\": avg_val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection:torch.Size([2, 32, 5]), box_reg:torch.Size([2, 20]), attention_weights:torch.Size([2, 32, 5]), num_boxes:torch.Size([2, 5])\n",
      "detection_scores:torch.Size([2, 32, 1]), topk_indices:torch.Size([2, 5, 1]), detection_topk:torch.Size([2, 5, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[411], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m CardDetectorMultiBox(num_cells\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, num_anchors\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 6\u001b[0m output_tensor \u001b[39m=\u001b[39m model(input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Leonard\\anaconda3\\envs\\pytorch_nn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[409], line 47\u001b[0m, in \u001b[0;36mCardDetectorMultiBox.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     43\u001b[0m detection_topk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(detection, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, index\u001b[39m=\u001b[39mtopk_indices)\n\u001b[0;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdetection_scores:\u001b[39m\u001b[39m{\u001b[39;00mdetection_scores\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, topk_indices:\u001b[39m\u001b[39m{\u001b[39;00mtopk_indices\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, detection_topk:\u001b[39m\u001b[39m{\u001b[39;00mdetection_topk\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m box_regression_topk \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mgather(box_regression, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, index\u001b[39m=\u001b[39;49mtopk_indices)\n\u001b[0;32m     51\u001b[0m boxes \u001b[39m=\u001b[39m []\n\u001b[0;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m boxes\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(2, 3, 224, 224)\n",
    "\n",
    "model = CardDetectorMultiBox(num_cells=16, num_anchors=2)\n",
    "model.eval()\n",
    "\n",
    "output_tensor = model(input_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
