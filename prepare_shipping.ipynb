{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import os\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1000\n",
    "VAL_SIZE = TRAIN_SIZE + 100\n",
    "TEST_SIZE = VAL_SIZE + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"aug_train\"\n",
    "val = \"aug_val\"\n",
    "test = \"aug_test\"\n",
    "\n",
    "os.makedirs(f\"./data/{train}\", exist_ok=True)\n",
    "os.makedirs(f\"./data/{val}\", exist_ok=True)\n",
    "os.makedirs(f\"./data/{test}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_offsets_to_center(x, y, w, h):\n",
    "    cx = int(x) + int(w)/2\n",
    "    cy = int(y) + int(h)/2\n",
    "    return str(cx), str(cy)\n",
    "\n",
    "def fix_positions(positions_joined):\n",
    "    positions = mit.chunked(positions_joined, n=4)\n",
    "    fixed_positions = []\n",
    "    for position in positions:\n",
    "        cx, cy = recalculate_offsets_to_center(*position)\n",
    "        fixed_positions.extend([cx, cy, position[2], position[3]])\n",
    "    return fixed_positions\n",
    "\n",
    "def prep_log_line(line, new_dir):\n",
    "    old_path = line[0]\n",
    "    \n",
    "    path_list = old_path.split('/')\n",
    "    for idx, part in enumerate(path_list):\n",
    "        if part == \"augmented_test\":\n",
    "            path_list[idx] = new_dir\n",
    "    \n",
    "    new_path = '/'.join(path_list)\n",
    "    \n",
    "    all_positions = line[1:]\n",
    "    fixed_positions = fix_positions(all_positions)\n",
    "    \n",
    "    new_line = [new_path] + fixed_positions\n",
    "    new_line = ','.join(new_line) + '\\n'\n",
    "    \n",
    "    return old_path, new_path, new_line\n",
    "\n",
    "\n",
    "train_set = []\n",
    "val_set = []\n",
    "test_set = []\n",
    "\n",
    "train_lines = []\n",
    "val_lines = []\n",
    "test_lines = []\n",
    "\n",
    "with open('./data/labels_test.csv', 'r') as read_object:\n",
    "    csv_reader = reader(read_object)\n",
    "    csv_reader.__next__()  # skip header\n",
    "    for i, line in enumerate(csv_reader):\n",
    "        if i < TRAIN_SIZE:\n",
    "            old_path, new_path, new_line = prep_log_line(line, train)\n",
    "            train_set.append((old_path, new_path))\n",
    "            train_lines.append(new_line)\n",
    "        if i >= TRAIN_SIZE and i < VAL_SIZE:\n",
    "            old_path, new_path, new_line = prep_log_line(line, val)\n",
    "            val_set.append((old_path, new_path))\n",
    "            val_lines.append(new_line)\n",
    "        if i >= VAL_SIZE and i < TEST_SIZE:\n",
    "            old_path, new_path, new_line = prep_log_line(line, test)\n",
    "            test_set.append((old_path, new_path))\n",
    "            test_lines.append(new_line)\n",
    "        if i > TEST_SIZE:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('./data/augmented_test/1_1.png', './data/aug_train/1_1.png'),\n",
       "  ('./data/augmented_test/1_2.png', './data/aug_train/1_2.png')],\n",
       " [('./data/augmented_test/1060_1.png', './data/aug_val/1060_1.png'),\n",
       "  ('./data/augmented_test/1060_2.png', './data/aug_val/1060_2.png')],\n",
       " [('./data/augmented_test/10618_1.png', './data/aug_test/10618_1.png'),\n",
       "  ('./data/augmented_test/10618_2.png', './data/aug_test/10618_2.png')])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[:2], val_set[:2], test_set[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for (old, new) in train_set:\n",
    "    img = Image.open(old)\n",
    "    img.save(new)\n",
    "    \n",
    "for (old, new) in val_set:\n",
    "    img = Image.open(old)\n",
    "    img.save(new)\n",
    "\n",
    "for (old, new) in test_set:\n",
    "    img = Image.open(old)\n",
    "    img.save(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_labels.csv\", \"w\") as data_pairs:\n",
    "       data_pairs.write(\n",
    "           \"imagename,x1,y1,w1,h1,x2,y2,w2,h2,x3,y3,w3,h3,x4,y4,w4,h4,x5,y5,w5,h5\\n\"\n",
    "       )\n",
    "       for line in train_lines:\n",
    "           data_pairs.write(line)\n",
    "\n",
    "with open(\"val_labels.csv\", \"w\") as data_pairs:\n",
    "       data_pairs.write(\n",
    "           \"imagename,x1,y1,w1,h1,x2,y2,w2,h2,x3,y3,w3,h3,x4,y4,w4,h4,x5,y5,w5,h5\\n\"\n",
    "       )\n",
    "       for line in val_lines:\n",
    "           data_pairs.write(line)\n",
    "\n",
    "with open(\"test_labels.csv\", \"w\") as data_pairs:\n",
    "       data_pairs.write(\n",
    "           \"imagename,x1,y1,w1,h1,x2,y2,w2,h2,x3,y3,w3,h3,x4,y4,w4,h4,x5,y5,w5,h5\\n\"\n",
    "       )\n",
    "       for line in test_lines:\n",
    "           data_pairs.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsiete_pytorch_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
